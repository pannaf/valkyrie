{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getenv('TAVILY_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sqlite3\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "db_url = \"https://storage.googleapis.com/benchmarks-artifacts/travel-db/travel2.sqlite\"\n",
    "local_file = \"travel2.sqlite\"\n",
    "# The backup lets us restart for each tutorial section\n",
    "backup_file = \"travel2.backup.sqlite\"\n",
    "overwrite = False\n",
    "if overwrite or not os.path.exists(local_file):\n",
    "    response = requests.get(db_url)\n",
    "    response.raise_for_status()  # Ensure the request was successful\n",
    "    with open(local_file, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    # Backup - we will use this to \"reset\" our DB in each section\n",
    "    shutil.copy(local_file, backup_file)\n",
    "# Convert the flights to present time for our tutorial\n",
    "conn = sqlite3.connect(local_file)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "tables = pd.read_sql(\n",
    "    \"SELECT name FROM sqlite_master WHERE type='table';\", conn\n",
    ").name.tolist()\n",
    "tdf = {}\n",
    "for t in tables:\n",
    "    tdf[t] = pd.read_sql(f\"SELECT * from {t}\", conn)\n",
    "\n",
    "example_time = pd.to_datetime(\n",
    "    tdf[\"flights\"][\"actual_departure\"].replace(\"\\\\N\", pd.NaT)\n",
    ").max()\n",
    "current_time = pd.to_datetime(\"now\").tz_localize(example_time.tz)\n",
    "time_diff = current_time - example_time\n",
    "\n",
    "tdf[\"bookings\"][\"book_date\"] = (\n",
    "    pd.to_datetime(tdf[\"bookings\"][\"book_date\"].replace(\"\\\\N\", pd.NaT), utc=True)\n",
    "    + time_diff\n",
    ")\n",
    "\n",
    "datetime_columns = [\n",
    "    \"scheduled_departure\",\n",
    "    \"scheduled_arrival\",\n",
    "    \"actual_departure\",\n",
    "    \"actual_arrival\",\n",
    "]\n",
    "for column in datetime_columns:\n",
    "    tdf[\"flights\"][column] = (\n",
    "        pd.to_datetime(tdf[\"flights\"][column].replace(\"\\\\N\", pd.NaT)) + time_diff\n",
    "    )\n",
    "\n",
    "for table_name, df in tdf.items():\n",
    "    df.to_sql(table_name, conn, if_exists=\"replace\", index=False)\n",
    "del df\n",
    "del tdf\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "db = local_file  # We'll be using this local file as our DB in this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'You must be a member of an organization to use the API. Please contact us through our help center at help.openai.com.', 'type': 'invalid_request_error', 'param': None, 'code': 'no_organization'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 43\u001b[0m\n\u001b[1;32m     37\u001b[0m         top_k_idx_sorted \u001b[38;5;241m=\u001b[39m top_k_idx[np\u001b[38;5;241m.\u001b[39margsort(\u001b[38;5;241m-\u001b[39mscores[top_k_idx])]\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m     39\u001b[0m             {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_docs[idx], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[idx]} \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m top_k_idx_sorted\n\u001b[1;32m     40\u001b[0m         ]\n\u001b[0;32m---> 43\u001b[0m retriever \u001b[38;5;241m=\u001b[39m \u001b[43mVectorStoreRetriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;129m@tool\u001b[39m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlookup_policy\u001b[39m(query: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m     48\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Consult the company policies to check whether certain options are permitted.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    Use this before making any flight changes performing other 'write' events.\"\"\"\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 24\u001b[0m, in \u001b[0;36mVectorStoreRetriever.from_docs\u001b[0;34m(cls, docs, oai_client)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_docs\u001b[39m(\u001b[38;5;28mcls\u001b[39m, docs, oai_client):\n\u001b[0;32m---> 24\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43moai_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-embedding-3-small\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpage_content\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     vectors \u001b[38;5;241m=\u001b[39m [emb\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;28;01mfor\u001b[39;00m emb \u001b[38;5;129;01min\u001b[39;00m embeddings\u001b[38;5;241m.\u001b[39mdata]\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(docs, vectors, oai_client)\n",
      "File \u001b[0;32m~/code/artemis/.v-arti/lib/python3.12/site-packages/openai/resources/embeddings.py:114\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[0;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    108\u001b[0m         embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[1;32m    109\u001b[0m             base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m         )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/artemis/.v-arti/lib/python3.12/site-packages/openai/_base_client.py:1240\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1228\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1235\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1236\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1237\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1238\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1239\u001b[0m     )\n\u001b[0;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/code/artemis/.v-arti/lib/python3.12/site-packages/openai/_base_client.py:921\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    914\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    920\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/artemis/.v-arti/lib/python3.12/site-packages/openai/_base_client.py:1020\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1017\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1019\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1023\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1024\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1027\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1028\u001b[0m )\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'You must be a member of an organization to use the API. Please contact us through our help center at help.openai.com.', 'type': 'invalid_request_error', 'param': None, 'code': 'no_organization'}}"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import openai\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "response = requests.get(\n",
    "    \"https://storage.googleapis.com/benchmarks-artifacts/travel-db/swiss_faq.md\"\n",
    ")\n",
    "response.raise_for_status()\n",
    "faq_text = response.text\n",
    "\n",
    "docs = [{\"page_content\": txt} for txt in re.split(r\"(?=\\n##)\", faq_text)]\n",
    "\n",
    "\n",
    "class VectorStoreRetriever:\n",
    "    def __init__(self, docs: list, vectors: list, oai_client):\n",
    "        self._arr = np.array(vectors)\n",
    "        self._docs = docs\n",
    "        self._client = oai_client\n",
    "\n",
    "    @classmethod\n",
    "    def from_docs(cls, docs, oai_client):\n",
    "        embeddings = oai_client.embeddings.create(\n",
    "            model=\"text-embedding-3-small\", input=[doc[\"page_content\"] for doc in docs]\n",
    "        )\n",
    "        vectors = [emb.embedding for emb in embeddings.data]\n",
    "        return cls(docs, vectors, oai_client)\n",
    "\n",
    "    def query(self, query: str, k: int = 5) -> list[dict]:\n",
    "        embed = self._client.embeddings.create(\n",
    "            model=\"text-embedding-3-small\", input=[query]\n",
    "        )\n",
    "        # \"@\" is just a matrix multiplication in python\n",
    "        scores = np.array(embed.data[0].embedding) @ self._arr.T\n",
    "        top_k_idx = np.argpartition(scores, -k)[-k:]\n",
    "        top_k_idx_sorted = top_k_idx[np.argsort(-scores[top_k_idx])]\n",
    "        return [\n",
    "            {**self._docs[idx], \"similarity\": scores[idx]} for idx in top_k_idx_sorted\n",
    "        ]\n",
    "\n",
    "\n",
    "retriever = VectorStoreRetriever.from_docs(docs, openai.Client())\n",
    "\n",
    "\n",
    "@tool\n",
    "def lookup_policy(query: str) -> str:\n",
    "    \"\"\"Consult the company policies to check whether certain options are permitted.\n",
    "    Use this before making any flight changes performing other 'write' events.\"\"\"\n",
    "    docs = retriever.query(query, k=2)\n",
    "    return \"\\n\\n\".join([doc[\"page_content\"] for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Create and populate the 'workouts' table\n",
    "conn = sqlite3.connect('fitness.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create workouts table\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS workouts (\n",
    "    workout_id INTEGER PRIMARY KEY,\n",
    "    name TEXT,\n",
    "    goal TEXT,\n",
    "    intensity TEXT,\n",
    "    description TEXT\n",
    ")\n",
    "''')\n",
    "\n",
    "# Insert sample data\n",
    "workouts = [\n",
    "    ('Full Body Strength', 'muscle gain', 'high', 'A high-intensity workout focusing on full-body strength.'),\n",
    "    ('Cardio Blast', 'weight loss', 'medium', 'A medium-intensity cardio workout for weight loss.'),\n",
    "    ('Yoga for Flexibility', 'flexibility', 'low', 'A low-intensity yoga workout to improve flexibility.'),\n",
    "]\n",
    "\n",
    "cursor.executemany('''\n",
    "INSERT INTO workouts (name, goal, intensity, description)\n",
    "VALUES (?, ?, ?, ?)\n",
    "''', workouts)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'workout_id': 1, 'name': 'Full Body Strength', 'goal': 'muscle gain', 'intensity': 'high', 'description': 'A high-intensity workout focusing on full-body strength.'}\n",
      "{'workout_id': 4, 'name': 'Full Body Strength', 'goal': 'muscle gain', 'intensity': 'high', 'description': 'A high-intensity workout focusing on full-body strength.'}\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "from typing import Optional, List, Dict\n",
    "\n",
    "# Assuming you have already created and populated a SQLite database named 'fitness.db'\n",
    "# with a table 'workouts' that has columns: 'workout_id', 'name', 'goal', 'intensity', and 'description'.\n",
    "\n",
    "# Define the search_workouts tool\n",
    "def search_workouts(goal: str, intensity: Optional[str] = None) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Search for workouts based on goal and intensity.\n",
    "\n",
    "    Args:\n",
    "        goal (str): The fitness goal, e.g., 'weight loss', 'muscle gain'.\n",
    "        intensity (Optional[str]): The intensity level, e.g., 'low', 'medium', 'high'.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: A list of workout dictionaries matching the search criteria.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect('fitness.db')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    query = \"SELECT * FROM workouts WHERE goal = ?\"\n",
    "    params = [goal]\n",
    "\n",
    "    if intensity:\n",
    "        query += \" AND intensity = ?\"\n",
    "        params.append(intensity)\n",
    "\n",
    "    cursor.execute(query, params)\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    # Fetch column names to create a list of dictionaries\n",
    "    column_names = [description[0] for description in cursor.description]\n",
    "    workouts = [dict(zip(column_names, row)) for row in rows]\n",
    "\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    return workouts\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    goal = \"muscle gain\"\n",
    "    intensity = \"high\"\n",
    "    results = search_workouts(goal, intensity)\n",
    "    for workout in results:\n",
    "        print(workout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".v-arti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
